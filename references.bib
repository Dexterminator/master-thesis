
@online{16_1thtip2d,
  title = {16.2. threading — {{Higher}}-level threading interface — {{Python}} 2.7.11 documentation},
  url = {https://docs.python.org/2/library/threading.html},
  timestamp = {2016-02-16T14:44:32Z},
  urldate = {2016-02-16},
  file = {16.2. threading — Higher-level threading interface — Python 2.7.11 documentation:/Users/dexterg/Library/Application Support/Zotero/Profiles/e340dsms.default/zotero/storage/PGKP45BQ/threading.html:}
}

@online{16_1mpip2d,
  title = {16.6. multiprocessing — {{Process}}-based “threading” interface — {{Python}} 2.7.11 documentation},
  url = {https://docs.python.org/2/library/multiprocessing.html#all-platforms},
  timestamp = {2016-02-01T09:10:47Z},
  urldate = {2016-02-01},
  file = {16.6. multiprocessing — Process-based “threading” interface — Python 2.7.11 documentation:/Users/dexterg/Library/Application Support/Zotero/Profiles/e340dsms.default/zotero/storage/AH9DP6ZD/multiprocessing.html:}
}

@online{26_2tppp2d,
  title = {26.4. {{The Python Profilers}} — {{Python}} 2.7.11 documentation},
  url = {https://docs.python.org/2/library/profile.html},
  timestamp = {2016-05-18T07:58:45Z},
  urldate = {2016-05-18},
  file = {26.4. The Python Profilers — Python 2.7.11 documentation:/Users/dexterg/Library/Application Support/Zotero/Profiles/e340dsms.default/zotero/storage/3GAPWGIB/profile.html:}
}

@article{che_2014_amdahl_alfmmp,
  title = {Amdahl’s law for multithreaded multicore processors},
  volume = {74},
  issn = {0743-7315},
  url = {http://www.sciencedirect.com/science/article/pii/S0743731514001142},
  doi = {10.1016/j.jpdc.2014.06.012},
  abstract = {In this paper, we conduct performance scaling analysis of multithreaded multicore processors (MMPs) for parallel computing. We propose a thread-level closed-queuing network model covering a fairly large design space, accounting for hardware scaling models, coarse-grain, fine-grain, and simultaneous multithreading (SMT) cores, shared resources, including cache, memory, and critical sections. We then derive a closed-form solution for this model in terms of speedup performance measure. This solution makes it possible to analyze performance scaling properties of MMPs along multiple dimensions. In particular, we show that for the parallelizable part of the workload, the speedup, in the absence of resource contention, is no longer just a linear function of parallel processing unit counts, as predicted by Amdahl’s law, but also a strong function of workload characteristics, ranging from strong memory-bound to strong CPU-bound workloads. We also find that with core multithreading, super linear speedup, higher than that predicted by Amdahl’s law, may be achieved for the parallelizable part of the workload, if core threads exhibit strong cache affinity and the workload is strongly memory-bound. Then, we derive a tight speedup upper bound in the presence of both memory resource contention and critical section for multicore processors with single-threaded cores. This speedup upper bound indicates that with resource contention among threads, whether it is due to shared memory or critical section, a sequential term is guaranteed to emerge from the parallelizable part of the workload, fundamentally limiting the scalability of multicore processors for parallel computing, in addition to the sequential part of the workload, as dictated by Amdahl’s law. As a result, to improve speedup performance for MMPs, one should strive to enhance memory parallelism and confine critical sections as locally as possible, e.g.,~to the smallest possible number of threads in the same core.},
  timestamp = {2016-01-22T10:27:37Z},
  number = {10},
  journaltitle = {Journal of Parallel and Distributed Computing},
  shortjournal = {Journal of Parallel and Distributed Computing},
  author = {Che, Hao and Nguyen, Minh},
  urldate = {2016-01-22},
  date = {2014-10},
  pages = {3056--3069},
  keywords = {Amdahl’s law,Closed queuing network,Multithreaded multicore processor,Speedup},
  file = {ScienceDirect Snapshot:/Users/dexterg/Library/Application Support/Zotero/Profiles/e340dsms.default/zotero/storage/BFKWFIFE/S0743731514001142.html:;amdahls-law-for-multicore.pdf:/Users/dexterg/Library/Application Support/Zotero/Profiles/e340dsms.default/zotero/storage/EURDANJI/amdahls-law-for-multicore.pdf:application/pdf}
}

@unpublished{beazley_150745UTC_introduction_aitpc,
  title = {An {{Introduction}} to {{Python Concurrency}}},
  url = {http://www.slideshare.net/dabeaz/an-introduction-to-python-concurrency?next_slideshow=1},
  timestamp = {2016-02-12T13:48:09Z},
  author = {Beazley, David},
  urldate = {2016-02-01},
  year = {15:07:45 UTC}
}

@book{mishra_2014_beginning_bacd,
  title = {Beginning {{Apache Cassandra Development}}},
  isbn = {978-1-4842-0142-8},
  abstract = {Beginning Apache Cassandra Development introduces you to one of the most robust and best-performing NoSQL database platforms on the planet. Apache Cassandra is a document database following the JSON document model. It is specifically designed to manage large amounts of data across many commodity servers without there being any single point of failure. This design approach makes Apache Cassandra a robust and easy-to-implement platform when high availability is needed.Apache Cassandra can be used by developers in Java, PHP, Python, and JavaScript—the primary and most commonly used languages. In Beginning Apache Cassandra Development, author and Cassandra expert Vivek Mishra takes you through using Apache Cassandra from each of these primary languages. Mishra also covers the Cassandra Query Language (CQL), the Apache Cassandra analog to SQL. You'll learn to develop applications sourcing data from Cassandra, query that data, and deliver it at speed to your application's users.Cassandra is one of the leading NoSQL databases, meaning you get unparalleled throughput and performance without the sort of processing overhead that comes with traditional proprietary databases. Beginning Apache Cassandra Development will therefore help you create applications that generate search results quickly, stand up to high levels of demand, scale as your user base grows, ensure operational simplicity, and—not least—provide delightful user experiences.},
  pagetotal = {235},
  timestamp = {2016-04-06T07:26:15Z},
  langid = {english},
  publisher = {{Apress}},
  author = {Mishra, Vivek},
  date = {2014-12-12},
  keywords = {Computers / Databases / Data Mining,Computers / Data Processing,Computers / Software Development & Engineering / General,Political Science / Public Affairs & Administration}
}

@online{holovaty_chapter_c1itd,
  title = {Chapter 1: {{Introduction}} to {{Django}}},
  url = {http://www.djangobook.com/en/2.0/chapter01.html},
  timestamp = {2016-04-05T13:20:36Z},
  titleaddon = {The Django Book},
  author = {Holovaty, Adrian and Kaplan-Moss, Jacob},
  urldate = {2016-04-05},
  file = {Chapter 1\: Introduction to Django:/Users/dexterg/Library/Application Support/Zotero/Profiles/e340dsms.default/zotero/storage/Z6MR6HXP/chapter01.html:}
}

@article{amdahl_2013_computer_caaal,
  title = {Computer {{Architecture}} and {{Amdahl}}'s {{Law}}},
  volume = {46},
  issn = {0018-9162},
  doi = {10.1109/MC.2013.418},
  abstract = {An autobiographical overview of Gene Amdah's professional career reviews his early achievements and describes for the first time some important details of his talk at the 1967 Spring Joint Computer Conference in Atlantic City and the heated discussions that followed. The author provides much-needed clarifications, most notably his original performance formula as presented nearly 50 years ago.},
  timestamp = {2016-01-22T10:30:00Z},
  number = {12},
  journaltitle = {Computer},
  shortjournal = {Computer},
  author = {Amdahl, G.M.},
  date = {2013-12},
  pages = {38--46},
  keywords = {Amdahl's Law,Biographies,computer architecture,Gene Amdah,performance analysis,professional career},
  file = {IEEE Xplore Abstract Record:/Users/dexterg/Library/Application Support/Zotero/Profiles/e340dsms.default/zotero/storage/63AM5SMM/abs_all.html:;IEEE Xplore Full Text PDF:/Users/dexterg/Library/Application Support/Zotero/Profiles/e340dsms.default/zotero/storage/TSPUNDRH/Amdahl - 2013 - Computer Architecture and Amdahl's Law.pdf:application/pdf}
}

@article{moore_1998_cramming_cmcoic,
  title = {Cramming {{More Components Onto Integrated Circuits}}},
  volume = {86},
  issn = {0018-9219},
  doi = {10.1109/JPROC.1998.658762},
  abstract = {Not Available},
  timestamp = {2016-02-01T13:43:05Z},
  number = {1},
  journaltitle = {Proceedings of the IEEE},
  shortjournal = {Proc. IEEE},
  author = {Moore, G.E.},
  date = {1998-01},
  pages = {82--85},
  keywords = {Aerospace electronics,Costs,Home computing,Integrated circuit reliability,Integrated circuit technology,Portable computers,Semiconductor films,Space technology,Switches,Telephony},
  file = {IEEE Xplore Abstract Record:/Users/dexterg/Library/Application Support/Zotero/Profiles/e340dsms.default/zotero/storage/C7W9IH2C/articleDetails.html:;IEEE Xplore Full Text PDF:/Users/dexterg/Library/Application Support/Zotero/Profiles/e340dsms.default/zotero/storage/NZ2TG838/Moore - 1998 - Cramming More Components Onto Integrated Circuits.pdf:application/pdf}
}

@book{slatkin_2015_effective_ep5swtwbp,
  edition = {1 edition},
  title = {Effective {{Python}}: 59 {{Specific Ways}} to {{Write Better Python}}},
  isbn = {978-0-13-403428-7},
  shorttitle = {Effective {{Python}}},
  abstract = {It's easy to start writing code with Python: that's why the language is so immensely popular. However, Python has unique strengths, charms, and expressivity that can be hard to grasp at first -- as well as hidden pitfalls that can easily trip you up if you aren't aware of them. Effective Python will help you harness the full power of Python to write exceptionally robust, efficient, maintainable, and well-performing code. Utilizing the concise, scenario-driven style pioneered in Scott Meyers's best-selling Effective C++, Brett Slatkin brings together 59 Python best practices, tips, shortcuts, and realistic code examples from expert programmers.   Through realistic examples, Slatkin uncovers little-known Python quirks, intricacies, and idioms that powerfully impact code behavior and performance. You'll learn how to choose the most efficient and effective way to accomplish key tasks when multiple options exist, and how to write code that's easier to understand, maintain, and improve.   Drawing on his deep understanding of Python's capabilities, Slatkin offers practical advice for each major area of development with both Python 3.x and Python 2.x. Coverage includes:    Algorithms  Objects  Concurrency  Collaboration  Built-in modules  Production techniques  And more   Each section contains specific, actionable guidelines organized into items, each with carefully worded advice supported by detailed technical arguments and illuminating examples. Using Effective Python, you can systematically improve all the Python code you write: not by blindly following rules or mimicking incomprehensible idioms, but by gaining a deep understanding of the technical reasons why they make sense.},
  pagetotal = {256},
  timestamp = {2016-02-16T15:29:31Z},
  langid = {english},
  publisher = {{Addison-Wesley Professional}},
  author = {Slatkin, Brett},
  date = {2015-03-08},
  file = {effective-python.pdf:/Users/dexterg/Library/Application Support/Zotero/Profiles/e340dsms.default/zotero/storage/TVHDJGTC/effective-python.pdf:application/pdf}
}

@inproceedings{ahmad_2015_efficient_epoppwossm,
  title = {Efficient parallelization of path planning workload on single-chip shared-memory multicores},
  doi = {10.1109/HPEC.2015.7322455},
  abstract = {Path planning problems greatly arise in many applications where the objective is to find the shortest path from a given source to destination. In this paper, we explore the comparison of programming languages in the context of parallel workload analysis. We characterize parallel versions of path planning algorithms, such as the Dijkstra's Algorithm, across C/C++ and Python languages. Programming language comparisons are done to analyze fine grain scalability and efficiency using a single-socket shared memory multicore processor. Architectural studies, such as understanding cache effects, are also undertaken to analyze bottlenecks for each parallelization strategy. Our results show that a right parallelization strategy for path planning yields scalability on a commercial multicore processor. However, several shortcomings exist in the parallel Python language that must be accounted for by HPC researchers.},
  eventtitle = {2015 IEEE High Performance Extreme Computing Conference (HPEC)},
  timestamp = {2016-02-01T16:30:38Z},
  booktitle = {2015 {{IEEE High Performance Extreme Computing Conference}} ({{HPEC}})},
  author = {Ahmad, M. and Lakshminarasimhan, K. and Khan, O.},
  date = {2015-09},
  pages = {1--6},
  keywords = {Convergence,graph theory,graph workload parallelization,high performance computing,HPC,Instruction sets,parallel algorithm,parallel algorithms,Parallel processing,parallel Python language,path planning,programming language,programming languages,Roads,Scalability,shared memory systems,Signal processing algorithms,single-chip shared-memory multicore},
  file = {path-planning.pdf:/Users/dexterg/Library/Application Support/Zotero/Profiles/e340dsms.default/zotero/storage/K9ZSIHBA/path-planning.pdf:application/pdf;IEEE Xplore Abstract Record:/Users/dexterg/Library/Application Support/Zotero/Profiles/e340dsms.default/zotero/storage/KWQ3ZS5T/login.html:}
}

@online{glossary_gp2d,
  title = {Glossary — {{Python}} 2.7.11 documentation},
  url = {https://docs.python.org/2/glossary.html#term-global-interpreter-lock},
  timestamp = {2016-02-16T14:36:07Z},
  urldate = {2016-02-16},
  file = {Glossary — Python 2.7.11 documentation:/Users/dexterg/Library/Application Support/Zotero/Profiles/e340dsms.default/zotero/storage/FTNQWHB2/glossary.html:}
}

@article{binet_2010_harnessing_hmsaiia,
  title = {Harnessing multicores: {{Strategies}} and implementations in {{ATLAS}}},
  volume = {219},
  issn = {1742-6596},
  url = {http://stacks.iop.org/1742-6596/219/i=4/a=042002},
  doi = {10.1088/1742-6596/219/4/042002},
  shorttitle = {Harnessing multicores},
  abstract = {Computers are no longer getting faster: instead, they are growing more and more CPUs, each of which is no faster than the previous generation. This increase in the number of cores evidently calls for more parallelism in HENP software. If end-users' stand-alone analysis applications are relatively easy to modify, LHC experiments frameworks, being mostly written with a single 'thread' of execution in mind and consequent code bases, are on the other hand more challenging to parallelize. Widespread and inconsiderate changes so close to data taking are out of the equation: we need clear strategies and guidelines to reap the benefits out of the multicore/manycore era while minimizing the code changes.},
  timestamp = {2016-01-29T15:15:46Z},
  langid = {english},
  number = {4},
  journaltitle = {Journal of Physics: Conference Series},
  shortjournal = {J. Phys.: Conf. Ser.},
  author = {Binet, S. and Calafiura, P. and Snyder, S. and Wiedenmann, W. and Winklmeier, F.},
  urldate = {2016-01-29},
  date = {2010},
  pages = {042002},
  file = {IOP Full Text PDF:/Users/dexterg/Library/Application Support/Zotero/Profiles/e340dsms.default/zotero/storage/DGSUWQWJ/Binet et al. - 2010 - Harnessing multicores Strategies and implementati.pdf:application/pdf}
}

@article{cai_2005_performance_otpotpplfsapsc,
  title = {On the {{Performance}} of the {{Python Programming Language}} for {{Serial}} and {{Parallel Scientific Computations}}},
  volume = {13},
  issn = {1058-9244},
  url = {http://www.hindawi.com/journals/sp/2005/619804/abs/},
  doi = {10.1155/2005/619804},
  abstract = {This article addresses the performance of scientific applications that use the Python programming language. First, we investigate several techniques for improving the computational efficiency of serial Python codes. Then, we discuss the basic programming techniques in Python for parallelizing serial scientific applications. It is shown that an efficient implementation of the array-related operations is essential for achieving good parallel performance, as for the serial case. Once the array-related operations are efficiently implemented, probably using a mixed-language implementation, good serial and parallel performance become achievable. This is confirmed by a set of numerical experiments. Python is also shown to be well suited for writing high-level parallel programs.},
  timestamp = {2016-01-21T15:01:01Z},
  langid = {english},
  number = {1},
  journaltitle = {Scientific Programming},
  shortjournal = {Sci. Program.},
  author = {Cai, Xing and Langtangen, Hans Petter and Moe, Halvard},
  urldate = {2016-01-21},
  date = {2005},
  pages = {31--56},
  file = {Full Text PDF:/Users/dexterg/Library/Application Support/Zotero/Profiles/e340dsms.default/zotero/storage/9RRB6MCC/Cai et al. - 2005 - On the Performance of the Python Programming Langu.pdf:application/pdf;Snapshot:/Users/dexterg/Library/Application Support/Zotero/Profiles/e340dsms.default/zotero/storage/SIXQNZJA/abs.html:}
}

@article{singh_2013_parallel_padpwprfmm,
  title = {Parallel astronomical data processing with {{Python}}: {{Recipes}} for multicore machines},
  volume = {2},
  issn = {2213-1337},
  url = {http://www.sciencedirect.com/science/article/pii/S2213133713000085},
  doi = {10.1016/j.ascom.2013.04.002},
  shorttitle = {Parallel astronomical data processing with {{Python}}},
  abstract = {High performance computing has been used in various fields of astrophysical research. But most of it is implemented on massively parallel systems (supercomputers) or graphical processing unit clusters. With the advent of multicore processors in the last decade, many serial software codes have been re-implemented in parallel mode to utilize the full potential of these processors. In this paper, we propose parallel processing recipes for multicore machines for astronomical data processing. The target audience is astronomers who use Python as their preferred scripting language and who may be using PyRAF/IRAF for data processing. Three problems of varied complexity were benchmarked on three different types of multicore processors to demonstrate the benefits, in terms of execution time, of parallelizing data processing tasks. The native multiprocessing module available in Python makes it a relatively trivial task to implement the parallel code. We have also compared the three multiprocessing approaches—Pool/Map, Process/Queue and Parallel Python. Our test codes are freely available and can be downloaded from our website.},
  timestamp = {2016-01-27T09:30:37Z},
  journaltitle = {Astronomy and Computing},
  shortjournal = {Astronomy and Computing},
  author = {Singh, Navtej and Browne, Lisa-Marie and Butler, Ray},
  urldate = {2016-01-27},
  date = {2013-08},
  pages = {1--10},
  keywords = {Astronomical data processing,Deconvolution,Multicore programming,Parallel computing,Parallel Python,Python multiprocessing},
  file = {ScienceDirect Snapshot:/Users/dexterg/Library/Application Support/Zotero/Profiles/e340dsms.default/zotero/storage/CABXFQ5G/S2213133713000085.html:;parallel-astro.pdf:/Users/dexterg/Library/Application Support/Zotero/Profiles/e340dsms.default/zotero/storage/INH7C6Q7/parallel-astro.pdf:application/pdf}
}

@article{rey_2013_parallel_pocmcip,
  title = {Parallel optimal choropleth map classification in {{PySAL}}},
  volume = {27},
  issn = {1365-8816},
  url = {http://www-tandfonline-com.focus.lib.kth.se/doi/abs/10.1080/13658816.2012.752094},
  doi = {10.1080/13658816.2012.752094},
  timestamp = {2016-02-04T15:27:52Z},
  number = {5},
  journaltitle = {International Journal of Geographical Information Science},
  shortjournal = {International Journal of Geographical Information Science},
  author = {Rey, Sergio J. and Anselin, Luc and Pahle, Robert and Kang, Xing and Stephens, Philip},
  urldate = {2016-02-04},
  date = {2013-05-01},
  pages = {1023--1039},
  file = {Snapshot:/Users/dexterg/Library/Application Support/Zotero/Profiles/e340dsms.default/zotero/storage/QI4V67RF/13658816.2012.html:;pysal-parallel.pdf:/Users/dexterg/Library/Application Support/Zotero/Profiles/e340dsms.default/zotero/storage/W5GZZKXD/pysal-parallel.pdf:application/pdf}
}

@book{palach_2014_parallel_ppwp,
  title = {Parallel {{Programming}} with {{Python}}},
  isbn = {978-1-78328-839-7},
  abstract = {A fast, easy-to-follow and clear tutorial to help you develop Parallel computing systems using Python. Along with explaining the fundamentals, the book will also introduce you to slightly advanced concepts and will help you in implementing these techniques in the real world.If you are an experienced Python programmer and are willing to utilize the available computing resources by parallelizing applications in a simple way, then this book is for you. You are required to have a basic knowledge of Python development to get the most of this book.},
  pagetotal = {124},
  timestamp = {2016-02-02T08:26:38Z},
  langid = {english},
  publisher = {{Packt Publishing}},
  author = {Palach, Jan},
  date = {2014-04-24},
  keywords = {Computers / Programming Languages / Python,Computers / Programming / Parallel},
  file = {Parallel-Programming-with-Python.pdf:/Users/dexterg/Library/Application Support/Zotero/Profiles/e340dsms.default/zotero/storage/N78ZTMQ3/Parallel-Programming-with-Python.pdf:application/pdf}
}

@online{noller_pep_p0,
  title = {{{PEP}} 0371},
  url = {https://www.python.org/dev/peps/pep-0371/},
  abstract = {The official home of the Python Programming Language},
  timestamp = {2016-02-12T14:39:21Z},
  titleaddon = {Python.org},
  author = {Noller, Jesse and Oudkerk, Richard},
  urldate = {2016-01-29},
  file = {Snapshot:/Users/dexterg/Library/Application Support/Zotero/Profiles/e340dsms.default/zotero/storage/46PS726P/pep-0371.html:}
}

@article{chow_2015_pipeline_ppiaote,
  title = {Pipeline pattern in an object-oriented, task-parallel environment},
  volume = {27},
  issn = {1532-0634},
  url = {http://onlinelibrary.wiley.com.focus.lib.kth.se/doi/10.1002/cpe.3305/abstract},
  doi = {10.1002/cpe.3305},
  abstract = {Task parallelism is an approach to parallel programming that has recently gained traction because of its compatibility with the predominant object-oriented languages and its low overhead compared to threading approaches. Parallel Task is an Open Source task-parallel compiler and runtime system for object-oriented languages, in particular Java. It is very flexible and expressive, demonstrated by the fact that it can be directly employed to implement most parallel computing patterns. The only notable exception has been the pipeline pattern where many data items are streamed through a number of processing stages. This is not surprising, as task parallelism is generally not compatible with the pipeline pattern. In this paper, we investigate how the pipeline pattern can be elegantly and efficiently implemented in a task-parallel environment. To do so, we extend Parallel Task with the concept of implicit futures to allow creating pipelines in an intuitive and object-oriented manner. Our experimental evaluation uses the extended Parallel Task to implement pipelines of different lengths and characteristics and compares with manual implementations. The evaluation demonstrates very good performance and scalability of the proposed task-parallel pipeline approach. Copyright © 2014 John Wiley \& Sons, Ltd.},
  timestamp = {2016-02-22T11:34:23Z},
  langid = {english},
  number = {5},
  journaltitle = {Concurrency and Computation: Practice and Experience},
  shortjournal = {Concurrency Computat.: Pract. Exper.},
  author = {Chow, Jonathan and Giacaman, Nasser and Sinnen, Oliver},
  urldate = {2016-02-22},
  date = {2015-04-10},
  pages = {1273--1291},
  keywords = {parallel skeletons,pipeline pattern,task parallelism},
  file = {Full Text PDF:/Users/dexterg/Library/Application Support/Zotero/Profiles/e340dsms.default/zotero/storage/7QS77UA2/Chow et al. - 2015 - Pipeline pattern in an object-oriented, task-paral.pdf:application/pdf;Snapshot:/Users/dexterg/Library/Application Support/Zotero/Profiles/e340dsms.default/zotero/storage/9PRS3G9C/abstract.html:}
}

@online{pythonimplementations_ppw,
  title = {{{PythonImplementations}} - {{Python Wiki}}},
  url = {https://wiki.python.org/moin/PythonImplementations},
  timestamp = {2016-04-08T11:21:49Z},
  urldate = {2016-04-08},
  file = {PythonImplementations - Python Wiki:/Users/dexterg/Library/Application Support/Zotero/Profiles/e340dsms.default/zotero/storage/VAV54JCC/PythonImplementations.html:}
}

@inproceedings{barany_2014_python_pipd,
  location = {{New York, NY, USA}},
  title = {Python {{Interpreter Performance Deconstructed}}},
  isbn = {978-1-4503-2916-3},
  url = {http://doi.acm.org/10.1145/2617548.2617552},
  doi = {10.1145/2617548.2617552},
  abstract = {The Python programming language is known for performing poorly on many tasks. While to some extent this is to be expected from a dynamic language, it is not clear how much each dynamic feature contributes to the costs of interpreting Python. In this study we attempt to quantify the costs of language features such as dynamic typing, reference counting for memory management, boxing of numbers, and late binding of function calls. We use an experimental compilation framework for Python that can make use of type annotations provided by the user to specialize the program as well as elide unnecessary reference counting operations and function lookups. The compiled programs run within the Python interpreter and use its internal API to implement language semantics. By separately enabling and disabling compiler optimizations, we can thus measure how much each language feature contributes to total execution time in the interpreter. We find that a boxed representation of numbers as heap objects is the single most costly language feature on numeric codes, accounting for up to 43\% of total execution time in our benchmark set. On symbolic object-oriented code, late binding of function and method calls costs up to 30\%. Redundant reference counting, dynamic type checks, and Python's elaborate function calling convention have comparatively smaller costs.},
  timestamp = {2016-01-27T09:27:07Z},
  booktitle = {Proceedings of the {{Workshop}} on {{Dynamic Languages}} and {{Applications}}},
  series = {Dyla'14},
  publisher = {{ACM}},
  author = {Barany, Gergö},
  urldate = {2016-01-27},
  date = {2014},
  pages = {5:1--5:9},
  keywords = {dynamic programming languages,interpreters,Python,reference counting,unboxing},
  file = {Python_Interpreter_Performance_Deconstructed.pdf:/Users/dexterg/Library/Application Support/Zotero/Profiles/e340dsms.default/zotero/storage/TEA5KHHN/Python_Interpreter_Performance_Deconstructed.pdf:application/pdf}
}

@online{krill_2015_python_psnhilp,
  title = {Python scales new heights in language popularity},
  url = {http://www.infoworld.com/article/3012442/application-development/python-scales-new-heights-in-language-popularity.html},
  abstract = {Python is increasingly in use as a first language in high school and universities, propelling it to its highest spot ever on the Tiobe index as well as a high ranking on the PyPL index},
  timestamp = {2016-02-12T12:59:25Z},
  titleaddon = {InfoWorld},
  author = {Krill, Paul},
  urldate = {2016-02-12},
  year = {2015-12-08T03:00-05:00},
  file = {Snapshot:/Users/dexterg/Library/Application Support/Zotero/Profiles/e340dsms.default/zotero/storage/RQAD7ECC/python-scales-new-heights-in-language-popularity.html:}
}

@article{gustafson_1988_reevaluating_ral,
  title = {Reevaluating {{Amdahl}}'s {{Law}}},
  volume = {31},
  issn = {0001-0782},
  url = {http://doi.acm.org/10.1145/42411.42415},
  doi = {10.1145/42411.42415},
  timestamp = {2016-01-22T10:38:07Z},
  number = {5},
  journaltitle = {Commun. ACM},
  shortjournal = {Commun ACM},
  author = {Gustafson, John L.},
  urldate = {2016-01-22},
  date = {1988-05},
  pages = {532--533},
  file = {gustafson-amdahl.pdf:/Users/dexterg/Library/Application Support/Zotero/Profiles/e340dsms.default/zotero/storage/2URXQ6C7/gustafson-amdahl.pdf:application/pdf}
}

@book{mccool_2012_structured_spppfec,
  location = {{Amsterdam; Boston}},
  edition = {1 edition},
  title = {Structured {{Parallel Programming}}: {{Patterns}} for {{Efficient Computation}}},
  isbn = {978-0-12-415993-8},
  shorttitle = {Structured {{Parallel Programming}}},
  abstract = {Programming is now parallel programming. Much as structured programming revolutionized traditional serial programming decades ago, a new kind of structured programming, based on patterns, is relevant to parallel programming today. Parallel computing experts and industry insiders Michael McCool, Arch Robison, and James Reinders describe how to design and implement maintainable and efficient parallel algorithms using a pattern-based approach. They present both theory and practice, and give detailed concrete examples using multiple programming models. Examples are primarily given using two of the most popular and cutting edge programming models for parallel programming: Threading Building Blocks, and Cilk Plus. These architecture-independent models enable easy integration into existing applications, preserve investments in existing code, and speed the development of parallel applications. Examples from realistic contexts illustrate patterns and themes in parallel algorithm design that are widely applicable regardless of implementation technology.The patterns-based approach offers structure and insight that developers can apply to a variety of parallel programming modelsDevelops a composable, structured, scalable, and machine-independent approach to parallel computingIncludes detailed examples in both Cilk Plus and the latest Threading Building Blocks, which support a wide variety of computers},
  pagetotal = {432},
  timestamp = {2016-02-11T10:13:33Z},
  langid = {english},
  publisher = {{Morgan Kaufmann}},
  author = {McCool, Michael and Reinders, James and Robison, Arch},
  date = {2012-07-09},
  file = {StructuredPP.pdf:/Users/dexterg/Library/Application Support/Zotero/Profiles/e340dsms.default/zotero/storage/X8P2IAKP/StructuredPP.pdf:application/pdf}
}

@book{herlihy_2012_art_taomprr,
  title = {The {{Art}} of {{Multiprocessor Programming}}, {{Revised Reprint}}},
  isbn = {978-0-12-397795-3},
  url = {http://proquest.safaribooksonline.com.focus.lib.kth.se/book/programming/9780123973375},
  abstract = {Revised and updated with improvements conceived in parallel programming courses, The Art of Multiprocessor Programming is an authoritative guide to multicore programming. It introduces a higher level set of software development skills than that needed for efficient single-core programming. This book provides comprehensive coverage of the new principles, algorithms, and tools necessary for effective multiprocessor programming. Students and professionals alike will benefit from thorough coverage of key multiprocessor programming issues. This revised edition incorporates much-demanded updates throughout the book, based on feedback and corrections reported from classrooms since 2008 Learn the fundamentals of programming multiple threads accessing shared memory Explore mainstream concurrent data structures and the key elements of their design, as well as synchronization techniques from simple locks to transactional memory systems Visit the companion site and download materials to support and enhance the learning experience},
  pagetotal = {536},
  timestamp = {2016-01-21T15:01:43Z},
  langid = {english},
  publisher = {{Morgan Kaufmann}},
  author = {Herlihy, Maurice and Shavit, Nir},
  urldate = {2016-01-21},
  date = {2012-06-25},
  file = {The_art_of_multiprocessor_programming.pdf:/Users/dexterg/Library/Application Support/Zotero/Profiles/e340dsms.default/zotero/storage/FQENXWK8/The_art_of_multiprocessor_programming.pdf:application/pdf}
}

@article{yavits_2014_effect_teocasoalims,
  title = {The effect of communication and synchronization on {{Amdahl}}’s law in multicore systems},
  volume = {40},
  issn = {0167-8191},
  url = {http://www.sciencedirect.com/science/article/pii/S0167819113001324},
  doi = {10.1016/j.parco.2013.11.001},
  abstract = {This work analyses the effects of sequential-to-parallel synchronization and inter-core communication on multicore performance, speedup and scaling from Amdahl’s law perspective. Analytical modeling supported by simulation leads to a modification of Amdahl’s law, reflecting lower than originally predicted speedup, due to these effects. In applications with high degree of data sharing, leading to intense inter-core connectivity requirements, the workload should be executed on a smaller number of larger cores. Applications requiring intense sequential-to-parallel synchronization, even highly parallelizable ones, may better be executed by the sequential core. To improve the scalability and performance speedup of a multicore, it is as important to address the synchronization and connectivity intensities of parallel algorithms as their parallelization factor.},
  timestamp = {2016-01-22T10:39:14Z},
  number = {1},
  journaltitle = {Parallel Computing},
  shortjournal = {Parallel Computing},
  author = {Yavits, L. and Morad, A. and Ginosar, R.},
  urldate = {2016-01-22},
  date = {2014-01},
  pages = {1--16},
  keywords = {Amdahl’s law,Analytical Performance Models,Multicore},
  file = {effect-of-communication.pdf:/Users/dexterg/Library/Application Support/Zotero/Profiles/e340dsms.default/zotero/storage/4N6TPWRP/effect-of-communication.pdf:application/pdf;ScienceDirect Snapshot:/Users/dexterg/Library/Application Support/Zotero/Profiles/e340dsms.default/zotero/storage/AMJBGIGH/S0167819113001324.html:}
}

@inproceedings{friborg_2009_three_tuiopfp,
  title = {Three {{Unique Implementations}} of {{Processes}} for {{PyCSP}}.},
  url = {http://www.researchgate.net/profile/Brian_Vinter/publication/221004402_Three_Unique_Implementations_of_Processes_for_PyCSP/links/0046352c13f97306f5000000.pdf},
  timestamp = {2016-01-29T15:38:08Z},
  booktitle = {{{CPA}}},
  author = {Friborg, Rune Møllegaard and Bjørndalen, John Markus and Vinter, Brian},
  urldate = {2016-01-29},
  date = {2009},
  pages = {277--292},
  file = {[PDF] from researchgate.net:/Users/dexterg/Library/Application Support/Zotero/Profiles/e340dsms.default/zotero/storage/PNDSP5PN/Friborg et al. - 2009 - Three Unique Implementations of Processes for PyCS.pdf:application/pdf}
}

@online{what_wim,
  title = {What is {{MySQL}}?},
  url = {http://dev.mysql.com/doc/refman/5.1/en/what-is-mysql.html},
  timestamp = {2016-04-05T13:54:46Z},
  urldate = {2016-04-05},
  file = {MySQL \:\: MySQL 5.1 Reference Manual \:\: 1.3.1 What is MySQL?:/Users/dexterg/Library/Application Support/Zotero/Profiles/e340dsms.default/zotero/storage/VDGDBGBW/what-is-mysql.html:}
}


