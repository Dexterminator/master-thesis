The results in the previous chapter are discussed below, in an effort to explain them. In addition, final conclusions
about the thesis as a whole are drawn.

\section{Dataset benchmarks discussion}
\subsection{Tiny dataset discussion}
Dataset 1, with comparatively few rows, shows poor results when parallelizing. For every worker number, only slowdown can be observed.
The real time values for 10 and 12 workers show high standard deviations when comparing with the average value. It is conceivable that
tasks such as creating processes have a more noticable impact for the low execution time.

The profiling session for the main process for the tiny dataset showed that \code{aggregate\_result} takes up 70\% of the time. Since this is the function
that performs the main parallel processing of the dataset, about 30\% of the execution time is overhead due to for example header detection
and making trade ID:s unique. Since aggregate\_result takes 0.4 seconds (15.7\% of execution time ) more to execute than it takes for a single worker to finish,
it appears as though parallelization and aggregating the partial results result in noticable overhead for the tiny dataset.
It is conceivable that the above results in the fact that only slowdown can be observed when parallelizing the tiny dataset.

Even without the parallel aggregation step, the tiny dataset still results in slowdown.

A steady, close to linear increase in memory usage can be observed, resulting in total memory usage several times above what is
used for the sequential program.

\subsection{Small dataset discussion}
For dataset 2, some speedup scaling can be observed, with the maximum value around 2.1. As more workers are added, speedup is increased,
flattening out around 8 workers. This fits with the fact that the testing machine has 8 cores, effectively making it able to utilize 
true parallelism for a maximum of 8 workers. The impact of adding more workers decreases with each one that is added. In the profiling session
\code{post\_process\_parallel} is shown to take up a relatively large portion of the execution time (22.5\%). Since this function is a separate,
sequential and constant step, it is not affected by parallelization and therefore takes up varying percantages of the total time. Since more parallelization
leads to faster execution of the parallel portion of the code, the post processing becomes more signifcant as workers are added, contributing to the fact
that adding more workers results in less and less increase in speedup.

Without the post processing step, the small dataset gets slightly better speedup for 8 workers, 2.7X instead of 2.11X. This is still not close to
the performance model calculations, which can be seen as disappointing.

The memory usage grows in a similar manner to dataset 1, though the values are greater.
Real time shows relatively low standard deviations compared to the total time, indicating that real time is fairly accurate for each worker
value.

\subsection{Medium dataset discussion}
Dataset 3 shows greater speedup than dataset 2, with a similar shape to the speedup by worker curve. The maximum speedup is
around 3.8, evening out around 8 workers, once again showing the best results around the machine's core number. This further suggests that larger
individal workload, this time a result of the larger dataset size, results in better speedup. Real time again shows
low standard deviation. Memory usage for the worker numbers with lthe largest speedup values is around 3 GB for dataset 3, demonstrating
that a large price in memory usage is paid for paralellization, which may impact performance negatively for large dataset sizes and
worker numbers.

The profiling session for the main process shows that \code{aggregate\_result} (30.138 s) takes a similar amount of time to the execution of
the worker processes (30.050 s). This suggests that parallelization overhead is not a major part of the execution time for the medium dataset.
However, in the worker process the \code{process} function (handling the main dataset processing) takes up 28.802 s of the total 30.050 s that the
worker takes to execute. This suggests a small overhead in the form of worker startup (4\%).
The post processing step takes up about 7.0\% of the execution time for 8 workers. This is less than for the small dataset, but may still contribute
to the fact that adding workers results in less increase in speedup.

Without the parallel processing, the medium dataset shows slighlty better speedup for 8 workers. However, this increase is only from 3.76X to 4.04X
speedup, meaning that it still has relatively low efficiency.

%\subsection{Dataset 4}
%With the even larger dataset 4, another increase in speedup can be observed. Once again, the trend of greater parallelization gains for larger
%dataset sizes holds. Interestingly, speedup increases slightly even past 8 workers, though it flattens out around 12 workers.
%Though the program is largely CPU bound, the reason for the increase when using a number of workers greater than the number of cores may be
%greater CPU utilization when waiting for I/O when extra workers are added, as the chance of finding a worker with CPU bound work to do increases. 
%Real time standard deviation follows the same, stable trend also for dataset 4. Memory usage when parallelizing this significantly larger dataset,
%ranging between 5 GB and 7 GB for the worker values with the greatest speedup.

\subsection{General benchmark trends}
In general, user time increases significantly with added workers, as is expected due to the greater total CPU utilization. Together with the
fact that memory usage increases linearly with worker number, this indicates that a noteworthy amount of system resources is required 
for parallelization as dataset sizes and number of workers grow large.

In general, larger datasets show greater speedup than smaller datasets.

\subsection{Memory usage and caching discussion}
The fact that memory usage increases as workers are added (though the overall problem size stays the same)
can be explained by the fact that the \code{multiprocessing} module creates separate, entirely
new processes. For each of these, the filters, mappings and other data relating to the transformation has to be stored in addition to the
base memory footprint of the process. 

As shown in section \ref{targeted_memory_profiling}, the mappings cached by the post process filter take up a clear majority of the memory,
and is substantial in size. The cache is in place in order to avoid many round trips to the database in order to get faster execution. However,
due to the fact that the worker processes cannot share any data when using \code{multiprocessing}, the data is duplicated across the processes,
resulting in a net increase in memory usage. For larger datasets, this increase in memory usage is very noticable, and therefore a
significant price to pay for speedup.

%As mentioned in the indidual dataset discussions, the reason for this
%is feasably that parallelization overhead and worker startup time becomes less significant as the row processing step takes up a larger portion
%of the execution time.

%Compared to the performance calculations in section \ref{performance_model_calculations} the speedup may seem disappointing. The reasons for this are likely
%manifold. The overhead of synchronization and \code{multiprocessing} process creation are not taken into account in any of the performance models,
%and may contribute to the smaller than expected speedup. Furthermore, as previously mentioned, each worker has to restart the connections to MySQL
%and Cassandra and also have to cache column mappings individually as \code{multiprocessing} does not allow for shared memory. Finally, the
%post processing step of making trade ID:s unique adds a significant sequential term to the transformation program.

\section{Conclusions}
This section outlines the final conclusions drawn from this thesis.

\subsection{Main conclusions}
Using Python \code{multiprocessing} for parallelization resulted in true parallel speedup, but was not without issues.
Sharing data using only message passing results in relatively safe and readable code since excessive sharing of data is avoided.
However, in the transformation program parallelized in this thesis, the fact that the processing pipeline including column mappings
needed to be stored for each worker resulted in more overhead both regarding worker startup and memory consumption. This
leads to the conclusion that users of multiprocessing need to be wary not only of communication and creation overhead associated
with processes (as opposed to threads), but also of overhead from worker startup and data duplication as a result of the message
passing model.

The transformation problem in this thesis, and parallel programs with expensive worker startup, are heavily influenced by the size
of the data. This means that developers faced with implemented parallelization of a similar systems should examine the data in their
problem domain in order to find an initial indication of whether the size of the datasets are, in general, large enough to benefit
from parallelization.

When parallelizing a complex system, as few assumptions as possible should be made before starting. In this thesis, the problem
involves I/O and database communication, suggesting that the problem may be I/O bound. However, further investigations proved that the problem
was largely CPU bound, making it suitable for \code{multiprocessing} in combination with a multicore machine. Investigation, rather than
assumption, are helpful when parallelizing a complex program involving both CPU and I/O tasks.

The method used in this thesis for finding parallelizability was relatively successful. When analyzing file formats for parallelizability,
inherently serial, extra overhead, and embarrassingly parallel formats where found. The implementation then focused on parallelizing
the extra overhead and embarrassingly parallel formats. This method could possibly be generalized to other parallelization problems
in complex systems, by identifying a subsystem that is easily parallelizable and focusing on that part rather than the system as a whole.
The subsystem might be either a subset of the code or of the datasets in the problem domain. In this thesis, the subsystem proved to be
large enough that the effort of parallelization was worthwhile, which is an analysis that should be made also in the general case of
parallelizing complex systems.

Developers should be wary of aggregation when parallelizing systems. In this thesis, aggregation manifested itself as making trade ID:s unique,
which was done by storing encountered ID:s. While storing state in this manner may appear as making rows dependant on each other, it proved
possible to extract the aggregation into a post-processing step. This extra step introduced overhead, but parallel speedup could still be 
observed for larger datasets. In conclusion, implementers of parallelization should look for aggregation in their system, conclude if this
can be extracted into a post processing step, and if this post processing step is small enough for parallelization to be beneficial.

\subsection{Delimitations}
The implementation and research in this thesis is limited to the parallelization of an existing program, and no new code for the core problem
of processing the datasets was written. Another delimitation of the thesis is that it does not compare different methods of parallelization,
and uses only the Python \code{multiprocessing} module.

\subsection{Future work}
This thesis focused on parallelization on a single computer. Since \code{multiprocessing} uses a message passing approach with serialized data,
it is conceivable that a future work in a distributed approach is interesting for the dataset transformation problem for larger datasets. Also,
conducting experiments on even larger datasets may be of value as the trend points to greater speedup the larger the dataset.
